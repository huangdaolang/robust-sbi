{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f367db0",
   "metadata": {},
   "source": [
    "# Performance evaluation\n",
    "\n",
    "### Model list: [NPE, RNPE, ABC, NPE-RS, ABC-RS]\n",
    "\n",
    "### Simulator list: [Ricker, OUP, Turin]\n",
    "\n",
    "### Metric list: [RMSE, MMD with temporal moment-based kernel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89afcedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import utils.metrics as metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import io\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simulators.oup import oup\n",
    "from simulators.ricker import ricker\n",
    "from simulators.turin import turin\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cf792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)\n",
    "\n",
    "def load_models(root_name: str, device: torch.device):\n",
    "    sum_net = torch.load(\"{root_name}/sum_net.pkl\".format(root_name=root_name), map_location=device)\n",
    "\n",
    "    density_estimator = torch.load(\"{root_name}/density_estimator.pkl\".format(root_name=root_name), map_location=device)\n",
    "\n",
    "    with open(\"{root_name}/posterior.pkl\".format(root_name=root_name), \"rb\") as handle:\n",
    "        posterior = CPU_Unpickler(handle).load() if device == torch.device('cpu') else pickle.load(handle)\n",
    "    \n",
    "    return sum_net, density_estimator, posterior\n",
    "\n",
    "\n",
    "def read_rnpe(model=\"oup\", var=1.0, degree=0, seed=1, theta=[0.5,1.0]):\n",
    "    file = f\"seed={seed}_degree={degree if float(degree)!=0 else 0}_var={var}_theta={theta}_{model}\"\n",
    "\n",
    "    results_dir = f\"objects/RNPE/{model}_final\"\n",
    "    fn = f\"{results_dir}/{file}.pickle\"\n",
    "\n",
    "    with open(fn, \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    return np.array(results['posterior_samples']['RNPE'])\n",
    "\n",
    "\n",
    "def sample_posteriors(posterior, obs, num):\n",
    "    return posterior.sample((num,), x=obs.reshape(1, 1, 100, -1), show_progress_bars=False)\n",
    "\n",
    "\n",
    "def temporalMomentsGeneral(Y, K=3, B=4e9):\n",
    "    N, Ns = Y.shape\n",
    "    tau = np.linspace(0, 100, Ns)\n",
    "    out = np.zeros((N, K))\n",
    "    Y = Y.detach().numpy()\n",
    "    for k in range(K):\n",
    "        for i in range(N):\n",
    "            out[i, k] = np.trapz(tau**(k) * Y[i], tau) + 1e-4\n",
    "    return np.log(out)\n",
    "\n",
    "def RMSE(gt, samples, p=1):\n",
    "    if p == 1:\n",
    "        dist = torch.mean(torch.abs(gt-samples))\n",
    "    elif p == 2:\n",
    "        dist = torch.sqrt(torch.mean((gt-samples)**2))\n",
    "    elif p == 3:\n",
    "        dist = torch.nn.functional.pairwise_distance(gt, samples, p=2).mean()\n",
    "    else:\n",
    "        dist = metrics.MMD_unweighted(samples, gt.reshape(-1, 2), lengthscale=metrics.median_heuristic(samples))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ddb78",
   "metadata": {},
   "source": [
    "# 1. Setup Lambda for NPE-RS and ABC-RS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4330a",
   "metadata": {},
   "source": [
    "## OUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb56f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations_oup = 100\n",
    "n_length_oup = 25\n",
    "\n",
    "n_samples_mmd = 1000\n",
    "n_sim = 50\n",
    "\n",
    "simulator = oup(N=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d63711",
   "metadata": {},
   "source": [
    "#### NPE-RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e8dae6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0, NPE-RS with lambda=1.0: MMD=0.012104899367684203\n",
      "OUP corrupted degree=0.0, NPE-RS with lambda=2.0: MMD=0.04322400392710015\n",
      "OUP corrupted degree=0.0, NPE-RS with lambda=3.0: MMD=0.030958189900746714\n",
      "Best lambda for OUP on NPE-RS with corruption degree 0.0: 1.0\n",
      "OUP corrupted degree=0.1, NPE-RS with lambda=1.0: MMD=0.08601572579174467\n",
      "OUP corrupted degree=0.1, NPE-RS with lambda=2.0: MMD=0.11768026783441352\n",
      "OUP corrupted degree=0.1, NPE-RS with lambda=3.0: MMD=0.15219836343072746\n",
      "Best lambda for OUP on NPE-RS with corruption degree 0.1: 1.0\n",
      "OUP corrupted degree=0.2, NPE-RS with lambda=1.0: MMD=0.19965814160283255\n",
      "OUP corrupted degree=0.2, NPE-RS with lambda=2.0: MMD=0.16163972089600645\n",
      "OUP corrupted degree=0.2, NPE-RS with lambda=3.0: MMD=0.18946449804597806\n",
      "Best lambda for OUP on NPE-RS with corruption degree 0.2: 2.0\n"
     ]
    }
   ],
   "source": [
    "degree_list = [0.0, 0.1, 0.2]\n",
    "lam_list = [1.0, 2.0, 3.0]\n",
    "\n",
    "\n",
    "for degree in degree_list:\n",
    "    obs = torch.tensor(np.load(f\"data/oup_obs_{int(degree * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_oup, n_length_oup)))\n",
    "    mmd_avg = np.zeros(len(lam_list))\n",
    "    for k, lam in enumerate(lam_list):        \n",
    "        mmd = np.zeros(n_sim)\n",
    "        for i in range(0, n_sim):\n",
    "            root_name = f\"objects/NPE/oup_new/degree={degree}_var=1.0_mmd_beta={lam}_theta=[0.5, 1.0]_num=1000_N=100/{i+1}\"\n",
    "            _, _, posterior = load_models(root_name, device)\n",
    "            post_samples = sample_posteriors(posterior, obs, n_samples_mmd)\n",
    "            \n",
    "            predictive_data = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "            for j in range(n_samples_mmd):\n",
    "                predictive_data[j] = simulator(post_samples[j])[0]\n",
    "    \n",
    "            pred_stat = torch.tensor(temporalMomentsGeneral(predictive_data))\n",
    "    \n",
    "            mmd[i] = float(metrics.MMD_unweighted(pred_stat, obs_stat, \n",
    "                           lengthscale=1))\n",
    "        mmd_avg[k] = np.mean(mmd[~np.isnan(mmd)])\n",
    "        print(f\"OUP corrupted degree={degree}, NPE-RS with lambda={lam}: MMD={mmd_avg[k]}\")\n",
    "    print(f\"Best lambda for OUP on NPE-RS with corruption degree {degree}: {lam_list[np.argmin(mmd_avg)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33841187",
   "metadata": {},
   "source": [
    "#### ABC-RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6a69d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0, ABC-RS with lambda=1: MMD=0.04348598569566878\n",
      "OUP corrupted degree=0.0, ABC-RS with lambda=2: MMD=0.03706016202911054\n",
      "OUP corrupted degree=0.0, ABC-RS with lambda=3: MMD=0.027946326200683068\n",
      "OUP corrupted degree=0.0, ABC-RS with lambda=4: MMD=0.028015741357104638\n",
      "OUP corrupted degree=0.0, ABC-RS with lambda=5: MMD=0.026910244729530648\n",
      "OUP corrupted degree=0.0, ABC-RS with lambda=10: MMD=0.033555406890993386\n",
      "Best lambda for OUP on ABC-RS with corruption degree 0.0: 5\n",
      "OUP corrupted degree=0.1, ABC-RS with lambda=1: MMD=0.7241154007271727\n",
      "OUP corrupted degree=0.1, ABC-RS with lambda=2: MMD=0.6378913970338096\n",
      "OUP corrupted degree=0.1, ABC-RS with lambda=3: MMD=0.4864801947605482\n",
      "OUP corrupted degree=0.1, ABC-RS with lambda=4: MMD=0.45007464976722517\n",
      "OUP corrupted degree=0.1, ABC-RS with lambda=5: MMD=0.416799328506095\n",
      "OUP corrupted degree=0.1, ABC-RS with lambda=10: MMD=0.35603762421384066\n",
      "Best lambda for OUP on ABC-RS with corruption degree 0.1: 10\n",
      "OUP corrupted degree=0.2, ABC-RS with lambda=1: MMD=0.9051409252747635\n",
      "OUP corrupted degree=0.2, ABC-RS with lambda=2: MMD=0.9681796877007762\n",
      "OUP corrupted degree=0.2, ABC-RS with lambda=3: MMD=0.9201298645085741\n",
      "OUP corrupted degree=0.2, ABC-RS with lambda=4: MMD=0.9050561567149153\n",
      "OUP corrupted degree=0.2, ABC-RS with lambda=5: MMD=0.9262602185810052\n",
      "OUP corrupted degree=0.2, ABC-RS with lambda=10: MMD=0.6371161752448716\n",
      "Best lambda for OUP on ABC-RS with corruption degree 0.2: 10\n"
     ]
    }
   ],
   "source": [
    "degree_list = [0.0, 0.1, 0.2]\n",
    "lam_list = [1, 2, 3, 4, 5, 10]\n",
    "\n",
    "for degree in degree_list:\n",
    "    obs = torch.tensor(np.load(f\"data/oup_obs_{int(degree * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_oup, n_length_oup)))\n",
    "    mmd_avg = np.zeros(len(lam_list))\n",
    "    for k, lam in enumerate(lam_list):        \n",
    "        mmd = np.zeros(n_sim)\n",
    "        for i in range(n_sim):\n",
    "            root_name = f\"objects/ABC/oup/degree={degree}/lambda={lam}/{i}\"\n",
    "            post_samples = np.load(root_name + '/posterior_robust.npy')\n",
    "            post_samples = torch.tensor(post_samples[np.random.choice(post_samples.shape[0], n_samples_mmd)])\n",
    "            \n",
    "            predictive_data = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "            for j in range(n_samples_mmd):\n",
    "                predictive_data[j] = simulator(post_samples[j])[0]\n",
    "    \n",
    "            pred_stat = torch.tensor(temporalMomentsGeneral(predictive_data))\n",
    "    \n",
    "            mmd[i] = float(metrics.MMD_unweighted(pred_stat, obs_stat, \n",
    "                           lengthscale=1))\n",
    "        mmd_avg[k] = np.mean(mmd[~np.isnan(mmd)])\n",
    "        print(f\"OUP corrupted degree={degree}, ABC-RS with lambda={lam}: MMD={mmd_avg[k]}\")\n",
    "    print(f\"Best lambda for OUP on ABC-RS with corruption degree {degree}: {lam_list[np.argmin(mmd_avg)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10222c6d",
   "metadata": {},
   "source": [
    "## Ricker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad21d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations_ricker = 100\n",
    "n_length_ricker = 100\n",
    "\n",
    "n_samples_mmd = 1000\n",
    "n_sim = 50\n",
    "\n",
    "simulator = ricker(N=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcf37c",
   "metadata": {},
   "source": [
    "#### NPE-RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6820deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricker corrupted degree=0.0, NPE-RS with lambda=1.0: MMD=0.08868219585875839\n",
      "Ricker corrupted degree=0.0, NPE-RS with lambda=2.0: MMD=0.10531050150119718\n",
      "Ricker corrupted degree=0.0, NPE-RS with lambda=3.0: MMD=0.16048733856418285\n",
      "Ricker corrupted degree=0.0, NPE-RS with lambda=5.0: MMD=0.20432387258646473\n",
      "Ricker corrupted degree=0.0, NPE-RS with lambda=10.0: MMD=0.2818680573878765\n",
      "Best lambda for Ricker on NPE-RS with corruption degree 0.0: 1.0\n",
      "Ricker corrupted degree=0.1, NPE-RS with lambda=1.0: MMD=0.28642005065121234\n",
      "Ricker corrupted degree=0.1, NPE-RS with lambda=2.0: MMD=0.2270608896447657\n",
      "Ricker corrupted degree=0.1, NPE-RS with lambda=3.0: MMD=0.30535392775018233\n",
      "Ricker corrupted degree=0.1, NPE-RS with lambda=5.0: MMD=0.3268486259108123\n",
      "Ricker corrupted degree=0.1, NPE-RS with lambda=10.0: MMD=0.38814205849332295\n",
      "Best lambda for Ricker on NPE-RS with corruption degree 0.1: 2.0\n",
      "Ricker corrupted degree=0.2, NPE-RS with lambda=1.0: MMD=0.3115958120943685\n",
      "Ricker corrupted degree=0.2, NPE-RS with lambda=2.0: MMD=0.4955454986373972\n",
      "Ricker corrupted degree=0.2, NPE-RS with lambda=3.0: MMD=0.42647487382322735\n",
      "Ricker corrupted degree=0.2, NPE-RS with lambda=5.0: MMD=0.4000846193791312\n",
      "Ricker corrupted degree=0.2, NPE-RS with lambda=10.0: MMD=0.4711327778290347\n",
      "Best lambda for Ricker on NPE-RS with corruption degree 0.2: 1.0\n"
     ]
    }
   ],
   "source": [
    "degree_list = [0.0, 0.1, 0.2]\n",
    "lam_list = [1.0, 2.0, 3.0, 5.0, 10.0]\n",
    "\n",
    "\n",
    "for degree in degree_list:\n",
    "    obs = torch.tensor(np.load(f\"data/ricker_obs_mix_{int(float(degree) * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_ricker, n_length_ricker)))\n",
    "    mmd_avg = np.zeros(len(lam_list))\n",
    "    for k, lam in enumerate(lam_list):        \n",
    "        mmd = np.zeros(n_sim)\n",
    "        for i in range(0, n_sim):\n",
    "            root_name = f\"objects/NPE/ricker/mix/degree={degree}_mmd_beta={lam}_theta=[4, 10]_num=1000/{i+1}\"\n",
    "            _, _, posterior = load_models(root_name, device)\n",
    "            post_samples = sample_posteriors(posterior, obs, n_samples_mmd)\n",
    "            \n",
    "            predictive_data = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "            for j in range(n_samples_mmd):\n",
    "                predictive_data[j] = simulator(post_samples[j])[0]\n",
    "    \n",
    "            pred_stat = torch.tensor(temporalMomentsGeneral(predictive_data))\n",
    "    \n",
    "            mmd[i] = float(metrics.MMD_unweighted(pred_stat, obs_stat, \n",
    "                           lengthscale=1))\n",
    "        mmd_avg[k] = np.mean(mmd[~np.isnan(mmd)])\n",
    "        print(f\"Ricker corrupted degree={degree}, NPE-RS with lambda={lam}: MMD={mmd_avg[k]}\")\n",
    "    print(f\"Best lambda for Ricker on NPE-RS with corruption degree {degree}: {lam_list[np.argmin(mmd_avg)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670db159",
   "metadata": {},
   "source": [
    "#### ABC-RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25959b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricker corrupted degree=0.0, ABC-RS with lambda=1: MMD=0.005767172948180837\n",
      "Ricker corrupted degree=0.0, ABC-RS with lambda=2: MMD=0.005728841590774645\n",
      "Ricker corrupted degree=0.0, ABC-RS with lambda=3: MMD=0.014609483353472811\n",
      "Ricker corrupted degree=0.0, ABC-RS with lambda=4: MMD=0.02558981398591236\n",
      "Ricker corrupted degree=0.0, ABC-RS with lambda=5: MMD=0.02946696851842721\n",
      "Ricker corrupted degree=0.0, ABC-RS with lambda=10: MMD=0.06533276035192817\n",
      "Best lambda for Ricker on ABC-RS with corruption degree 0.0: 2\n",
      "Ricker corrupted degree=0.1, ABC-RS with lambda=1: MMD=0.2718213878047113\n",
      "Ricker corrupted degree=0.1, ABC-RS with lambda=2: MMD=0.2166386489705339\n",
      "Ricker corrupted degree=0.1, ABC-RS with lambda=3: MMD=0.19601454058791679\n",
      "Ricker corrupted degree=0.1, ABC-RS with lambda=4: MMD=0.19796378541784315\n",
      "Ricker corrupted degree=0.1, ABC-RS with lambda=5: MMD=0.1560059810327139\n",
      "Ricker corrupted degree=0.1, ABC-RS with lambda=10: MMD=0.18245332968158234\n",
      "Best lambda for Ricker on ABC-RS with corruption degree 0.1: 5\n",
      "Ricker corrupted degree=0.2, ABC-RS with lambda=1: MMD=0.18043187895172239\n",
      "Ricker corrupted degree=0.2, ABC-RS with lambda=2: MMD=0.18680686372997532\n",
      "Ricker corrupted degree=0.2, ABC-RS with lambda=3: MMD=0.13363680478369974\n",
      "Ricker corrupted degree=0.2, ABC-RS with lambda=4: MMD=0.1939621680045716\n",
      "Ricker corrupted degree=0.2, ABC-RS with lambda=5: MMD=0.19027714884678026\n",
      "Ricker corrupted degree=0.2, ABC-RS with lambda=10: MMD=0.19866160747822068\n",
      "Best lambda for Ricker on ABC-RS with corruption degree 0.2: 3\n"
     ]
    }
   ],
   "source": [
    "degree_list = [0.0, 0.1, 0.2]\n",
    "lam_list = [1, 2, 3, 4, 5, 10]\n",
    "\n",
    "for degree in degree_list:\n",
    "    obs = torch.tensor(np.load(f\"data/ricker_obs_mix_{int(degree * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_ricker, n_length_ricker)))\n",
    "    mmd_avg = np.zeros(len(lam_list))\n",
    "    for k, lam in enumerate(lam_list):        \n",
    "        mmd = np.zeros(n_sim)\n",
    "        for i in range(n_sim):\n",
    "            root_name = f\"objects/ABC/ricker/degree={degree}/lambda={lam}/{i}\"\n",
    "            post_samples = np.load(root_name + '/posterior_robust.npy')\n",
    "            post_samples = torch.tensor(post_samples[np.random.choice(post_samples.shape[0], n_samples_mmd)])\n",
    "            \n",
    "            predictive_data = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "            for j in range(n_samples_mmd):\n",
    "                predictive_data[j] = simulator(post_samples[j])[0]\n",
    "    \n",
    "            pred_stat = torch.tensor(temporalMomentsGeneral(predictive_data))\n",
    "    \n",
    "            mmd[i] = float(metrics.MMD_unweighted(pred_stat, obs_stat, \n",
    "                           lengthscale=1))\n",
    "        mmd_avg[k] = np.mean(mmd[~np.isnan(mmd)])\n",
    "        print(f\"Ricker corrupted degree={degree}, ABC-RS with lambda={lam}: MMD={mmd_avg[k]}\")\n",
    "    print(f\"Best lambda for Ricker on ABC-RS with corruption degree {degree}: {lam_list[np.argmin(mmd_avg)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e573992",
   "metadata": {},
   "source": [
    "# 2. Final evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f677b",
   "metadata": {},
   "source": [
    "## OUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca617ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations_oup = 100\n",
    "n_length_oup = 25\n",
    "\n",
    "n_samples_mmd = 1000\n",
    "n_samples_rmse = 1000\n",
    "\n",
    "n_sim = 100\n",
    "\n",
    "simulator = oup(N=1)\n",
    "\n",
    "theta_gt = torch.tensor([0.5, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9f94e",
   "metadata": {},
   "source": [
    "### OUP RMSE (NPE family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6532e6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0\n",
      "NPE: RMSE mean=0.7925630547851324, RMSE std=0.6189539155079293\n",
      "RNPE: RMSE mean=0.7798082494735717, RMSE std=0.08754678141313765\n",
      "NPE-RS with lambda=1.0: RMSE mean=0.7372859045863152, RMSE std=0.6026562181259022\n",
      "OUP corrupted degree=0.1\n",
      "NPE: RMSE mean=1.2649758909642697, RMSE std=1.1900491524141108\n",
      "RNPE: RMSE mean=0.8717409908771515, RMSE std=0.10160560064131247\n",
      "NPE-RS with lambda=1.0: RMSE mean=0.6163115787506104, RMSE std=0.3190021981676373\n",
      "OUP corrupted degree=0.2\n",
      "NPE: RMSE mean=2.5887098464369775, RMSE std=2.7487078421648006\n",
      "RNPE: RMSE mean=0.9750068730115891, RMSE std=0.15094306281805106\n",
      "NPE-RS with lambda=2.0: RMSE mean=0.6315770514309407, RMSE std=0.35337456682942775\n"
     ]
    }
   ],
   "source": [
    "degree_lam_npe_rs = {'0.0': 1.0, '0.1': 1.0, '0.2': 2.0}\n",
    "\n",
    "oup_rmse_npe = np.zeros((3, 2))\n",
    "oup_rmse_rnpe = np.zeros((3, 2))\n",
    "oup_rmse_npe_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_npe_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/oup_obs_{int(float(degree) * 10)}.npy\"))\n",
    "    \n",
    "    rmse_npe = np.zeros(n_sim)\n",
    "    rmse_rnpe = np.zeros(n_sim)\n",
    "    rmse_npe_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):   \n",
    "        root_name = f'objects/NPE/oup_final/degree=0.0_var=1.0_none_beta=3.0_theta=[0.5, 1.0]_num=1000_N=100/{i+1}'\n",
    "        _, _, posterior_npe = load_models(root_name, device)\n",
    "        post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_rmse)\n",
    "        \n",
    "        root_name = f'objects/NPE/oup_final/degree={degree}_var=1.0_mmd_beta={lam}_theta=[0.5, 1.0]_num=1000_N=100/{i+1}'\n",
    "        _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "        post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_rmse)\n",
    "        \n",
    "        post_samples_rnpe = torch.tensor(read_rnpe(model=\"oup\", var=1, degree=degree, seed=i+1, theta='[0.5,1.0]'))[:n_samples_rmse]\n",
    "        \n",
    "        \n",
    "        rmse_npe[i] = float(RMSE(theta_gt, post_samples_npe, p=2))\n",
    "        rmse_rnpe[i] = float(RMSE(theta_gt, post_samples_rnpe, p=2))\n",
    "        rmse_npe_rs[i] = float(RMSE(theta_gt, post_samples_npe_rs, p=2))\n",
    "                               \n",
    "    oup_rmse_npe[k, 0] = np.mean(rmse_npe)\n",
    "    oup_rmse_npe[k, 1] = np.std(rmse_npe)\n",
    "    \n",
    "    oup_rmse_rnpe[k, 0] = np.mean(rmse_rnpe)\n",
    "    oup_rmse_rnpe[k, 1] = np.std(rmse_rnpe)\n",
    "                               \n",
    "    oup_rmse_npe_rs[k, 0] = np.mean(rmse_npe_rs)\n",
    "    oup_rmse_npe_rs[k, 1] = np.std(rmse_npe_rs)\n",
    "    \n",
    "    print(f\"OUP corrupted degree={degree}\")\n",
    "    print(f\"NPE: RMSE mean={oup_rmse_npe[k, 0]}, RMSE std={oup_rmse_npe[k, 1]}\")\n",
    "    print(f\"RNPE: RMSE mean={oup_rmse_rnpe[k, 0]}, RMSE std={oup_rmse_rnpe[k, 1]}\")\n",
    "    print(f\"NPE-RS with lambda={lam}: RMSE mean={oup_rmse_npe_rs[k, 0]}, RMSE std={oup_rmse_npe_rs[k, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9efb0b",
   "metadata": {},
   "source": [
    "### OUP RMSE (ABC family)\n",
    "\n",
    "We nned to do ABC separately as it use different set of lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7858d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0\n",
      "ABC: RMSE mean=0.49509559582020657, RMSE std=0.06467575409620172\n",
      "ABC-RS with lambda=5: RMSE mean=0.4418196542316118, RMSE std=0.06685935044476349\n",
      "OUP corrupted degree=0.1\n",
      "ABC: RMSE mean=1.2996316719499046, RMSE std=0.3686765148306931\n",
      "ABC-RS with lambda=15: RMSE mean=0.6165489532625812, RMSE std=0.22824126181335438\n",
      "OUP corrupted degree=0.2\n",
      "ABC: RMSE mean=5.370637510496948, RMSE std=2.3427128599919267\n",
      "ABC-RS with lambda=20: RMSE mean=0.8767756478055136, RMSE std=0.4821035779200563\n"
     ]
    }
   ],
   "source": [
    "degree_lam_abc_rs = {'0.0': 5, '0.1': 15, '0.2': 20}\n",
    "\n",
    "oup_rmse_abc = np.zeros((3, 2))\n",
    "oup_rmse_abc_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_abc_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/oup_obs_{int(float(degree) * 10)}.npy\"))\n",
    "       \n",
    "    rmse_abc = np.zeros(n_sim)\n",
    "    rmse_abc_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):\n",
    "        # share the root name\n",
    "        root_name = f\"objects/ABC/oup_final/degree={degree}/lambda={lam}/{i}\"\n",
    "        \n",
    "        # abc\n",
    "        post_samples_abc = np.load(root_name + '/posterior_normal.npy')\n",
    "        post_samples_abc = torch.tensor(post_samples_abc[np.random.choice(post_samples_abc.shape[0], n_samples_rmse)])\n",
    "\n",
    "        # abc_rs\n",
    "        post_samples_abc_rs = np.load(root_name + '/posterior_robust.npy')\n",
    "        post_samples_abc_rs = torch.tensor(post_samples_abc_rs[np.random.choice(post_samples_abc_rs.shape[0], n_samples_rmse)])\n",
    "\n",
    "        rmse_abc[i] = float(RMSE(theta_gt, post_samples_abc, p=2))\n",
    "        rmse_abc_rs[i] = float(RMSE(theta_gt, post_samples_abc_rs, p=2))\n",
    "        \n",
    "    oup_rmse_abc[k, 0] = np.mean(rmse_abc)\n",
    "    oup_rmse_abc[k, 1] = np.std(rmse_abc)\n",
    "    \n",
    "    oup_rmse_abc_rs[k, 0] = np.mean(rmse_abc_rs)\n",
    "    oup_rmse_abc_rs[k, 1] = np.std(rmse_abc_rs)\n",
    "    \n",
    "    print(f\"OUP corrupted degree={degree}\")\n",
    "    print(f\"ABC: RMSE mean={oup_rmse_abc[k, 0]}, RMSE std={oup_rmse_abc[k, 1]}\")\n",
    "    print(f\"ABC-RS with lambda={lam}: RMSE mean={oup_rmse_abc_rs[k, 0]}, RMSE std={oup_rmse_abc_rs[k, 1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d5d11",
   "metadata": {},
   "source": [
    "### OUP MMD (NPE family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dc934200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0\n",
      "NPE: MMD mean=0.0070277369812554585, MMD std=0.010243516876271171\n",
      "RNPE: MMD mean=0.011334007263055793, MMD std=0.009915834978669363\n",
      "NPE-RS with lambda=1.0: MMD mean=0.022377721632277688, MMD std=0.04952137444403441\n",
      "OUP corrupted degree=0.1\n",
      "NPE: MMD mean=0.3393863778075364, MMD std=0.14622658405849778\n",
      "RNPE: MMD mean=0.21543395248179795, MMD std=0.1259491349758079\n",
      "NPE-RS with lambda=1.0: MMD mean=0.08563636728201396, MMD std=0.09430481767122267\n",
      "OUP corrupted degree=0.2\n",
      "NPE: MMD mean=0.6459693757398669, MMD std=0.2916390504590604\n",
      "RNPE: MMD mean=0.48738906279377814, MMD std=0.2608236681747754\n",
      "NPE-RS with lambda=2.0: MMD mean=0.20954411375210164, MMD std=0.1700419374910337\n"
     ]
    }
   ],
   "source": [
    "degree_lam_npe_rs = {'0.0':1.0, '0.1':1.0, '0.2': 2.0}\n",
    "\n",
    "oup_mmd_npe = np.zeros((3, 2))\n",
    "oup_mmd_rnpe = np.zeros((3, 2))\n",
    "oup_mmd_npe_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_npe_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/oup_obs_{int(float(degree) * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_oup, n_length_oup)))\n",
    "       \n",
    "    mmd_npe = np.zeros(n_sim)\n",
    "    mmd_rnpe = np.zeros(n_sim)\n",
    "    mmd_npe_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):\n",
    "        # npe\n",
    "        root_name = f\"objects/NPE/oup_final/degree=0.0_var=1.0_none_beta=3.0_theta=[0.5, 1.0]_num=1000_N=100/{i+1}\"\n",
    "        _, _, posterior_npe = load_models(root_name, device)\n",
    "        post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_mmd)\n",
    "        \n",
    "        predictive_data_npe = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_npe[j] = simulator(post_samples_npe[j])[0]\n",
    "\n",
    "        pred_stat_npe = torch.tensor(temporalMomentsGeneral(predictive_data_npe))\n",
    "\n",
    "        mmd_npe[i] = float(metrics.MMD_unweighted(pred_stat_npe, obs_stat, lengthscale=1))\n",
    "        \n",
    "        # rnpe\n",
    "        post_samples_rnpe = torch.tensor(read_rnpe(model=\"oup\", var=1, degree=degree, seed=i+1, theta='[0.5,1.0]'))[:n_samples_mmd]\n",
    "\n",
    "        predictive_data_rnpe = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_rnpe[j] = simulator(post_samples_rnpe[j])[0]\n",
    "\n",
    "        pred_stat_rnpe = torch.tensor(temporalMomentsGeneral(predictive_data_rnpe))\n",
    "\n",
    "        mmd_rnpe[i] = float(metrics.MMD_unweighted(pred_stat_rnpe, obs_stat, lengthscale=1))\n",
    "        \n",
    "        # npe_rs\n",
    "        root_name = f\"objects/NPE/oup_final/degree={degree}_var=1.0_mmd_beta={lam}_theta=[0.5, 1.0]_num=1000_N=100/{i+1}\"\n",
    "        _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "        post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_mmd)\n",
    "\n",
    "        predictive_data_npe_rs = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_npe_rs[j] = simulator(post_samples_npe_rs[j])[0]\n",
    "\n",
    "        pred_stat_npe_rs = torch.tensor(temporalMomentsGeneral(predictive_data_npe_rs))\n",
    "\n",
    "        mmd_npe_rs[i] = float(metrics.MMD_unweighted(pred_stat_npe_rs, obs_stat, lengthscale=1))\n",
    "        \n",
    "    oup_mmd_npe[k, 0] = np.mean(mmd_npe[~np.isnan(mmd_npe)])\n",
    "    oup_mmd_npe[k, 1] = np.std(mmd_npe[~np.isnan(mmd_npe)])\n",
    "    \n",
    "    oup_mmd_rnpe[k, 0] = np.mean(mmd_rnpe[~np.isnan(mmd_rnpe)])\n",
    "    oup_mmd_rnpe[k, 1] = np.std(mmd_rnpe[~np.isnan(mmd_rnpe)])\n",
    "    \n",
    "    oup_mmd_npe_rs[k, 0] = np.mean(mmd_npe_rs[~np.isnan(mmd_npe_rs)])\n",
    "    oup_mmd_npe_rs[k, 1] = np.std(mmd_npe_rs[~np.isnan(mmd_npe_rs)])\n",
    "    \n",
    "    print(f\"OUP corrupted degree={degree}\")\n",
    "    print(f\"NPE: MMD mean={oup_mmd_npe[k, 0]}, MMD std={oup_mmd_npe[k, 1]}\")\n",
    "    print(f\"RNPE: MMD mean={oup_mmd_rnpe[k, 0]}, MMD std={oup_mmd_rnpe[k, 1]}\")\n",
    "    print(f\"NPE-RS with lambda={lam}: MMD mean={oup_mmd_npe_rs[k, 0]}, MMD std={oup_mmd_npe_rs[k, 1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7b273",
   "metadata": {},
   "source": [
    "### OUP MMD (ABC family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bd4080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0\n",
      "ABC: MMD mean=0.051694323171523386, MMD std=0.030256493560625913\n",
      "ABC-RS with lambda=5: MMD mean=0.02326028402970792, MMD std=0.020645582131445087\n",
      "OUP corrupted degree=0.1\n",
      "ABC: MMD mean=0.9074055313005361, MMD std=0.2066785989071141\n",
      "ABC-RS with lambda=15: MMD mean=0.26036175151166246, MMD std=0.16959001923327374\n",
      "OUP corrupted degree=0.2\n",
      "ABC: MMD mean=0.9359434314371308, MMD std=0.19424011524359938\n",
      "ABC-RS with lambda=20: MMD mean=0.49584723062468256, MMD std=0.37667546112109673\n"
     ]
    }
   ],
   "source": [
    "degree_lam_abc_rs = {'0.0': 5, '0.1': 15, '0.2': 20}\n",
    "\n",
    "oup_mmd_abc = np.zeros((3, 2))\n",
    "oup_mmd_abc_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_abc_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/oup_obs_{int(float(degree) * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_oup, n_length_oup)))\n",
    "       \n",
    "    mmd_abc = np.zeros(n_sim)\n",
    "    mmd_abc_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):\n",
    "        # share the root name\n",
    "        root_name = f\"objects/ABC/oup_final/degree={degree}/lambda={lam}/{i}\"\n",
    "        \n",
    "        # abc\n",
    "        post_samples_abc = np.load(root_name + '/posterior_normal.npy')\n",
    "        post_samples_abc = torch.tensor(post_samples_abc[np.random.choice(post_samples_abc.shape[0], n_samples_mmd)])\n",
    "\n",
    "        predictive_data_abc = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_abc[j] = simulator(post_samples_abc[j])[0]\n",
    "\n",
    "        pred_stat_abc = torch.tensor(temporalMomentsGeneral(predictive_data_abc))\n",
    "\n",
    "        mmd_abc[i] = float(metrics.MMD_unweighted(pred_stat_abc, obs_stat, \n",
    "                              lengthscale=1))\n",
    "        \n",
    "        # abc_rs\n",
    "        post_samples_abc_rs = np.load(root_name + '/posterior_robust.npy')\n",
    "        post_samples_abc_rs = torch.tensor(post_samples_abc_rs[np.random.choice(post_samples_abc_rs.shape[0], n_samples_mmd)])\n",
    "\n",
    "        predictive_data_abc_rs = torch.zeros(n_samples_mmd, n_length_oup)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_abc_rs[j] = simulator(post_samples_abc_rs[j])[0]\n",
    "\n",
    "        pred_stat_abc_rs = torch.tensor(temporalMomentsGeneral(predictive_data_abc_rs))\n",
    "\n",
    "        mmd_abc_rs[i] = float(metrics.MMD_unweighted(pred_stat_abc_rs, obs_stat, \n",
    "                              lengthscale=1))\n",
    "        \n",
    "    oup_mmd_abc[k, 0] = np.mean(mmd_abc[~np.isnan(mmd_abc)])\n",
    "    oup_mmd_abc[k, 1] = np.std(mmd_abc[~np.isnan(mmd_abc)])\n",
    "    \n",
    "    oup_mmd_abc_rs[k, 0] = np.mean(mmd_abc_rs[~np.isnan(mmd_abc_rs)])\n",
    "    oup_mmd_abc_rs[k, 1] = np.std(mmd_abc_rs[~np.isnan(mmd_abc_rs)])\n",
    "    \n",
    "    print(f\"OUP corrupted degree={degree}\")\n",
    "    print(f\"ABC: MMD mean={oup_mmd_abc[k, 0]}, MMD std={oup_mmd_abc[k, 1]}\")\n",
    "    print(f\"ABC-RS with lambda={lam}: MMD mean={oup_mmd_abc_rs[k, 0]}, MMD std={oup_mmd_abc_rs[k, 1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10869b",
   "metadata": {},
   "source": [
    "## Ricker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "722f183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations_ricker = 100\n",
    "n_length_ricker = 100\n",
    "\n",
    "n_samples_mmd = 1000\n",
    "n_samples_rmse = 1000\n",
    "n_sim = 100\n",
    "\n",
    "simulator = ricker(N=1)\n",
    "\n",
    "theta_gt_ricker = torch.tensor([4, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929fb1ff",
   "metadata": {},
   "source": [
    "### Ricker RMSE (NPE family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e93895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0\n",
      "NPE: RMSE mean=2.159665313065052, RMSE std=3.072399608646757\n",
      "RNPE: RMSE mean=3.272554533481598, RMSE std=0.3458116151400395\n",
      "NPE-RS with lambda=1.0: RMSE mean=2.186364681571722, RMSE std=2.6600947351637276\n",
      "OUP corrupted degree=0.1\n",
      "NPE: RMSE mean=7.862835259437561, RMSE std=1.5652844966705644\n",
      "RNPE: RMSE mean=5.505721306800842, RMSE std=0.5761808462790206\n",
      "NPE-RS with lambda=2.0: RMSE mean=2.1900993782281875, RMSE std=1.0142630566053492\n",
      "OUP corrupted degree=0.2\n",
      "NPE: RMSE mean=11.254029388427734, RMSE std=1.6961005782948435\n",
      "RNPE: RMSE mean=7.1370215463638305, RMSE std=1.1523687822492195\n",
      "NPE-RS with lambda=1.0: RMSE mean=4.659657540917396, RMSE std=4.147216315165953\n"
     ]
    }
   ],
   "source": [
    "degree_lam_npe_rs = {'0.0': 1.0, '0.1': 2.0, '0.2': 1.0}\n",
    "\n",
    "ricker_rmse_npe = np.zeros((3, 2))\n",
    "ricker_rmse_rnpe = np.zeros((3, 2))\n",
    "ricker_rmse_npe_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_npe_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/ricker_obs_mix_{int(float(degree) * 10)}.npy\"))\n",
    "    \n",
    "    rmse_npe = np.zeros(n_sim)\n",
    "    rmse_rnpe = np.zeros(n_sim)\n",
    "    rmse_npe_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):   \n",
    "        root_name = f'objects/NPE/ricker_final/degree=0.0_none_beta=1.0_theta=[4, 10]_num=1000/{i+1}'\n",
    "        _, _, posterior_npe = load_models(root_name, device)\n",
    "        post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_rmse)\n",
    "        \n",
    "        root_name = f'objects/NPE/ricker_final/degree={degree}_mmd_beta={lam}_theta=[4, 10]_num=1000/{i+1}'\n",
    "        _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "        post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_rmse)\n",
    "        \n",
    "        post_samples_rnpe = torch.tensor(read_rnpe(model=\"ricker\", var=1, degree=degree, seed=i+1, theta='[4,10]'))[:n_samples_rmse]\n",
    "        \n",
    "        \n",
    "        rmse_npe[i] = float(RMSE(theta_gt_ricker, post_samples_npe, p=2))\n",
    "        rmse_rnpe[i] = float(RMSE(theta_gt_ricker, post_samples_rnpe, p=2))\n",
    "        rmse_npe_rs[i] = float(RMSE(theta_gt_ricker, post_samples_npe_rs, p=2))\n",
    "                               \n",
    "    ricker_rmse_npe[k, 0] = np.mean(rmse_npe)\n",
    "    ricker_rmse_npe[k, 1] = np.std(rmse_npe)\n",
    "    \n",
    "    ricker_rmse_rnpe[k, 0] = np.mean(rmse_rnpe)\n",
    "    ricker_rmse_rnpe[k, 1] = np.std(rmse_rnpe)\n",
    "                               \n",
    "    ricker_rmse_npe_rs[k, 0] = np.mean(rmse_npe_rs)\n",
    "    ricker_rmse_npe_rs[k, 1] = np.std(rmse_npe_rs)\n",
    "    \n",
    "    print(f\"Ricker corrupted degree={degree}\")\n",
    "    print(f\"NPE: RMSE mean={ricker_rmse_npe[k, 0]}, RMSE std={ricker_rmse_npe[k, 1]}\")\n",
    "    print(f\"RNPE: RMSE mean={ricker_rmse_rnpe[k, 0]}, RMSE std={ricker_rmse_rnpe[k, 1]}\")\n",
    "    print(f\"NPE-RS with lambda={lam}: RMSE mean={ricker_rmse_npe_rs[k, 0]}, RMSE std={ricker_rmse_npe_rs[k, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b077442",
   "metadata": {},
   "source": [
    "### Ricker RMSE (ABC family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c02730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricker corrupted degree=0.0\n",
      "ABC: RMSE mean=1.4608000411195203, RMSE std=0.4392969559445925\n",
      "ABC-RS with lambda=2: RMSE mean=1.2027322280237103, RMSE std=0.5087569342337235\n",
      "Ricker corrupted degree=0.1\n",
      "ABC: RMSE mean=6.954336906258834, RMSE std=0.24572330168065148\n",
      "ABC-RS with lambda=5: RMSE mean=3.1578248301227183, RMSE std=1.0781114401159106\n",
      "Ricker corrupted degree=0.2\n",
      "ABC: RMSE mean=9.790066190478761, RMSE std=0.9581979221745782\n",
      "ABC-RS with lambda=3: RMSE mean=2.988856295848981, RMSE std=1.2768888852086335\n"
     ]
    }
   ],
   "source": [
    "degree_lam_abc_rs = {'0.0': 2, '0.1': 5, '0.2': 3}\n",
    "\n",
    "ricker_rmse_abc = np.zeros((3, 2))\n",
    "ricker_rmse_abc_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_abc_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/ricker_obs_mix_{int(float(degree) * 10)}.npy\"))\n",
    "       \n",
    "    rmse_abc = np.zeros(n_sim)\n",
    "    rmse_abc_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):\n",
    "        # share the root name\n",
    "        root_name = f\"objects/ABC/ricker_final/degree={degree}/lambda={lam}/{i}\"\n",
    "        \n",
    "        # abc\n",
    "        post_samples_abc = np.load(root_name + '/posterior_normal.npy')\n",
    "        post_samples_abc = torch.tensor(post_samples_abc[np.random.choice(post_samples_abc.shape[0], n_samples_rmse)])\n",
    "\n",
    "        # abc_rs\n",
    "        post_samples_abc_rs = np.load(root_name + '/posterior_robust.npy')\n",
    "        post_samples_abc_rs = torch.tensor(post_samples_abc_rs[np.random.choice(post_samples_abc_rs.shape[0], n_samples_rmse)])\n",
    "\n",
    "        rmse_abc[i] = float(RMSE(theta_gt_ricker, post_samples_abc, p=2))\n",
    "        rmse_abc_rs[i] = float(RMSE(theta_gt_ricker, post_samples_abc_rs, p=2))\n",
    "        \n",
    "    ricker_rmse_abc[k, 0] = np.mean(rmse_abc)\n",
    "    ricker_rmse_abc[k, 1] = np.std(rmse_abc)\n",
    "    \n",
    "    ricker_rmse_abc_rs[k, 0] = np.mean(rmse_abc_rs)\n",
    "    ricker_rmse_abc_rs[k, 1] = np.std(rmse_abc_rs)\n",
    "    \n",
    "    print(f\"Ricker corrupted degree={degree}\")\n",
    "    print(f\"ABC: RMSE mean={ricker_rmse_abc[k, 0]}, RMSE std={ricker_rmse_abc[k, 1]}\")\n",
    "    print(f\"ABC-RS with lambda={lam}: RMSE mean={ricker_rmse_abc_rs[k, 0]}, RMSE std={ricker_rmse_abc_rs[k, 1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2e4b5",
   "metadata": {},
   "source": [
    "### Ricker MMD (NPE family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48360787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUP corrupted degree=0.0\n",
      "NPE: MMD mean=0.03706105067511231, MMD std=0.06727287126878594\n",
      "RNPE: MMD mean=0.060767924199361306, MMD std=0.05112879165455601\n",
      "NPE-RS with lambda=1.0: MMD mean=0.09476873343865283, MMD std=0.1360528195996939\n",
      "OUP corrupted degree=0.1\n",
      "NPE: MMD mean=0.7407399593116799, MMD std=0.09144744914533502\n",
      "RNPE: MMD mean=0.5144580338583704, MMD std=0.19024194378245304\n",
      "NPE-RS with lambda=2.0: MMD mean=0.21128224107432303, MMD std=0.16095958734150315\n",
      "OUP corrupted degree=0.2\n",
      "NPE: MMD mean=1.062957432326659, MMD std=0.1665800264563046\n",
      "RNPE: MMD mean=0.7876811902890908, MMD std=0.2516543011128707\n",
      "NPE-RS with lambda=1.0: MMD mean=0.4162054194272693, MMD std=0.3729153105951972\n"
     ]
    }
   ],
   "source": [
    "degree_lam_npe_rs = {'0.0': 1.0, '0.1': 2.0, '0.2': 1.0}\n",
    "\n",
    "ricker_mmd_npe = np.zeros((3, 2))\n",
    "ricker_mmd_rnpe = np.zeros((3, 2))\n",
    "ricker_mmd_npe_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_npe_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/ricker_obs_mix_{int(float(degree) * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_ricker, n_length_ricker)))\n",
    "       \n",
    "    mmd_npe = np.zeros(n_sim)\n",
    "    mmd_rnpe = np.zeros(n_sim)\n",
    "    mmd_npe_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):\n",
    "        # npe\n",
    "        root_name = f\"objects/NPE/ricker_final/degree=0.0_none_beta=1.0_theta=[4, 10]_num=1000/{i+1}\"\n",
    "        _, _, posterior_npe = load_models(root_name, device)\n",
    "        post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_mmd)\n",
    "        \n",
    "        predictive_data_npe = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_npe[j] = simulator(post_samples_npe[j])[0]\n",
    "\n",
    "        pred_stat_npe = torch.tensor(temporalMomentsGeneral(predictive_data_npe))\n",
    "\n",
    "        mmd_npe[i] = float(metrics.MMD_unweighted(pred_stat_npe, obs_stat, lengthscale=1))\n",
    "        \n",
    "        # rnpe\n",
    "        post_samples_rnpe = torch.tensor(read_rnpe(model=\"ricker\", var=1, degree=degree, seed=i+1, theta='[4,10]'))[:n_samples_mmd]\n",
    "\n",
    "        predictive_data_rnpe = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_rnpe[j] = simulator(post_samples_rnpe[j])[0]\n",
    "\n",
    "        pred_stat_rnpe = torch.tensor(temporalMomentsGeneral(predictive_data_rnpe))\n",
    "\n",
    "        mmd_rnpe[i] = float(metrics.MMD_unweighted(pred_stat_rnpe, obs_stat, lengthscale=1))\n",
    "        \n",
    "        # npe_rs\n",
    "        root_name = f\"objects/NPE/ricker_final/degree={degree}_mmd_beta={lam}_theta=[4, 10]_num=1000/{i+1}\"\n",
    "        _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "        post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_mmd)\n",
    "\n",
    "        predictive_data_npe_rs = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_npe_rs[j] = simulator(post_samples_npe_rs[j])[0]\n",
    "\n",
    "        pred_stat_npe_rs = torch.tensor(temporalMomentsGeneral(predictive_data_npe_rs))\n",
    "\n",
    "        mmd_npe_rs[i] = float(metrics.MMD_unweighted(pred_stat_npe_rs, obs_stat, lengthscale=1))\n",
    "        \n",
    "    ricker_mmd_npe[k, 0] = np.mean(mmd_npe[~np.isnan(mmd_npe)])\n",
    "    ricker_mmd_npe[k, 1] = np.std(mmd_npe[~np.isnan(mmd_npe)])\n",
    "    \n",
    "    ricker_mmd_rnpe[k, 0] = np.mean(mmd_rnpe[~np.isnan(mmd_rnpe)])\n",
    "    ricker_mmd_rnpe[k, 1] = np.std(mmd_rnpe[~np.isnan(mmd_rnpe)])\n",
    "    \n",
    "    ricker_mmd_npe_rs[k, 0] = np.mean(mmd_npe_rs[~np.isnan(mmd_npe_rs)])\n",
    "    ricker_mmd_npe_rs[k, 1] = np.std(mmd_npe_rs[~np.isnan(mmd_npe_rs)])\n",
    "    \n",
    "    print(f\"Ricker corrupted degree={degree}\")\n",
    "    print(f\"NPE: MMD mean={ricker_mmd_npe[k, 0]}, MMD std={ricker_mmd_npe[k, 1]}\")\n",
    "    print(f\"RNPE: MMD mean={ricker_mmd_rnpe[k, 0]}, MMD std={ricker_mmd_rnpe[k, 1]}\")\n",
    "    print(f\"NPE-RS with lambda={lam}: MMD mean={ricker_mmd_npe_rs[k, 0]}, MMD std={ricker_mmd_npe_rs[k, 1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6b556",
   "metadata": {},
   "source": [
    "### Ricker MMD (ABC family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8f6bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricker corrupted degree=0.0\n",
      "ABC: MMD mean=0.011006514798503762, MMD std=0.006379625010296103\n",
      "ABC-RS with lambda=2: MMD mean=0.010748643338569562, MMD std=0.024220475619427403\n",
      "Ricker corrupted degree=0.1\n",
      "ABC: MMD mean=0.8466678177737447, MMD std=0.020180858060685626\n",
      "ABC-RS with lambda=5: MMD mean=0.17617922205863845, MMD std=0.14967006191022045\n",
      "Ricker corrupted degree=0.2\n",
      "ABC: MMD mean=1.1844820523373287, MMD std=0.04169950910295297\n",
      "ABC-RS with lambda=3: MMD mean=0.1798236737689743, MMD std=0.15902950406937638\n"
     ]
    }
   ],
   "source": [
    "degree_lam_abc_rs = {'0.0': 2, '0.1': 5, '0.2': 3}\n",
    "\n",
    "ricker_mmd_abc = np.zeros((3, 2))\n",
    "ricker_mmd_abc_rs = np.zeros((3, 2))\n",
    "\n",
    "for k, (degree, lam) in enumerate(degree_lam_abc_rs.items()):\n",
    "    obs = torch.tensor(np.load(f\"data/ricker_obs_mix_{int(float(degree) * 10)}.npy\"))\n",
    "    obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_ricker, n_length_ricker)))\n",
    "       \n",
    "    mmd_abc = np.zeros(n_sim)\n",
    "    mmd_abc_rs = np.zeros(n_sim)\n",
    "    for i in range(0, n_sim):\n",
    "        # share the root name\n",
    "        root_name = f\"objects/ABC/ricker_final/degree={degree}/lambda={lam}/{i}\"\n",
    "        \n",
    "        # abc\n",
    "        post_samples_abc = np.load(root_name + '/posterior_normal.npy')\n",
    "        post_samples_abc = torch.tensor(post_samples_abc[np.random.choice(post_samples_abc.shape[0], n_samples_mmd)])\n",
    "\n",
    "        predictive_data_abc = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_abc[j] = simulator(post_samples_abc[j])[0]\n",
    "\n",
    "        pred_stat_abc = torch.tensor(temporalMomentsGeneral(predictive_data_abc))\n",
    "\n",
    "        mmd_abc[i] = float(metrics.MMD_unweighted(pred_stat_abc, obs_stat, \n",
    "                              lengthscale=1))\n",
    "        \n",
    "        # abc_rs\n",
    "        post_samples_abc_rs = np.load(root_name + '/posterior_robust.npy')\n",
    "        post_samples_abc_rs = torch.tensor(post_samples_abc_rs[np.random.choice(post_samples_abc_rs.shape[0], n_samples_mmd)])\n",
    "\n",
    "        predictive_data_abc_rs = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "        for j in range(n_samples_mmd):\n",
    "            predictive_data_abc_rs[j] = simulator(post_samples_abc_rs[j])[0]\n",
    "\n",
    "        pred_stat_abc_rs = torch.tensor(temporalMomentsGeneral(predictive_data_abc_rs))\n",
    "\n",
    "        mmd_abc_rs[i] = float(metrics.MMD_unweighted(pred_stat_abc_rs, obs_stat, \n",
    "                              lengthscale=1))\n",
    "        \n",
    "    ricker_mmd_abc[k, 0] = np.mean(mmd_abc[~np.isnan(mmd_abc)])\n",
    "    ricker_mmd_abc[k, 1] = np.std(mmd_abc[~np.isnan(mmd_abc)])\n",
    "    \n",
    "    ricker_mmd_abc_rs[k, 0] = np.mean(mmd_abc_rs[~np.isnan(mmd_abc_rs)])\n",
    "    ricker_mmd_abc_rs[k, 1] = np.std(mmd_abc_rs[~np.isnan(mmd_abc_rs)])\n",
    "    \n",
    "    print(f\"Ricker corrupted degree={degree}\")\n",
    "    print(f\"ABC: MMD mean={ricker_mmd_abc[k, 0]}, MMD std={ricker_mmd_abc[k, 1]}\")\n",
    "    print(f\"ABC-RS with lambda={lam}: MMD mean={ricker_mmd_abc_rs[k, 0]}, MMD std={ricker_mmd_abc_rs[k, 1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e438",
   "metadata": {},
   "source": [
    "### Ricker prior misspecification RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ed556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricker prior misspecification\n",
      "NPE: RMSE mean=7.719186365604401, RMSE std=4.024103435366731\n",
      "RNPE: RMSE mean=7.707057628631592, RMSE std=2.8867418100218227\n",
      "NPE-RS: RMSE mean=6.461816523075104, RMSE std=4.3615884296198075\n"
     ]
    }
   ],
   "source": [
    "theta_gt_ricker = torch.tensor([4, 25])\n",
    "obs = torch.tensor(np.load(f\"data/ricker_obs_pm.npy\"))\n",
    "\n",
    "rmse_npe = np.zeros(n_sim)\n",
    "rmse_rnpe = np.zeros(n_sim)\n",
    "rmse_npe_rs = np.zeros(n_sim)\n",
    "for i in range(0, n_sim):   \n",
    "    root_name = f'objects/NPE/ricker_final/degree=0.2_none_beta=2.0_theta=[4, 25]_num=1000/{i+1}'\n",
    "    _, _, posterior_npe = load_models(root_name, device)\n",
    "    post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_rmse)\n",
    "\n",
    "    root_name = f'objects/NPE/ricker_final/degree=0.2_mmd_beta=5.0_theta=[4, 25]_num=1000/{i+1}'\n",
    "    _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "    post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_rmse)\n",
    "\n",
    "    post_samples_rnpe = torch.tensor(read_rnpe(model=\"ricker\", var=1, degree=0, seed=i+1, theta='[4,25]'))[:n_samples_rmse]\n",
    "\n",
    "    rmse_npe[i] = float(RMSE(theta_gt_ricker, post_samples_npe, p=2))\n",
    "    rmse_rnpe[i] = float(RMSE(theta_gt_ricker, post_samples_rnpe, p=2))\n",
    "    rmse_npe_rs[i] = float(RMSE(theta_gt_ricker, post_samples_npe_rs, p=2))\n",
    "    \n",
    "print(f\"Ricker prior misspecification\")\n",
    "print(f\"NPE: RMSE mean={np.mean(rmse_npe)}, RMSE std={np.std(rmse_npe)}\")\n",
    "print(f\"RNPE: RMSE mean={np.mean(rmse_rnpe)}, RMSE std={np.std(rmse_rnpe)}\")\n",
    "print(f\"NPE-RS: RMSE mean={np.mean(rmse_npe_rs)}, RMSE std={np.std(rmse_npe_rs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f697c",
   "metadata": {},
   "source": [
    "### Ricker prior misspecification MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a9654dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ricker prior misspecification\n",
      "NPE: MMD mean=0.16637261207515547, MMD std=0.15120399465017192\n",
      "RNPE: MMD mean=0.5352750061168536, MMD std=0.3971765945454501\n",
      "NPE-RS: MMD mean=0.1665071753268997, MMD std=0.25160294471773914\n"
     ]
    }
   ],
   "source": [
    "obs = torch.tensor(np.load(f\"data/ricker_obs_pm.npy\"))\n",
    "obs_stat = torch.tensor(temporalMomentsGeneral(obs.reshape(n_realizations_ricker, n_length_ricker)))\n",
    "\n",
    "mmd_npe = np.zeros(n_sim)\n",
    "mmd_rnpe = np.zeros(n_sim)\n",
    "mmd_npe_rs = np.zeros(n_sim)\n",
    "for i in range(0, n_sim):\n",
    "    # npe\n",
    "    root_name = f\"objects/NPE/ricker_final/degree=0.2_none_beta=2.0_theta=[4, 25]_num=1000/{i+1}\"\n",
    "    _, _, posterior_npe = load_models(root_name, device)\n",
    "    post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_mmd)\n",
    "\n",
    "    predictive_data_npe = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "    for j in range(n_samples_mmd):\n",
    "        predictive_data_npe[j] = simulator(post_samples_npe[j])[0]\n",
    "\n",
    "    pred_stat_npe = torch.tensor(temporalMomentsGeneral(predictive_data_npe))\n",
    "\n",
    "    mmd_npe[i] = float(metrics.MMD_unweighted(pred_stat_npe, obs_stat, lengthscale=1))\n",
    "\n",
    "    # rnpe\n",
    "    post_samples_rnpe = torch.tensor(read_rnpe(model=\"ricker\", var=1, degree=0, seed=i+1, theta='[4,25]'))[:n_samples_mmd]\n",
    "\n",
    "    predictive_data_rnpe = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "    for j in range(n_samples_mmd):\n",
    "        predictive_data_rnpe[j] = simulator(post_samples_rnpe[j])[0]\n",
    "\n",
    "    pred_stat_rnpe = torch.tensor(temporalMomentsGeneral(predictive_data_rnpe))\n",
    "\n",
    "    mmd_rnpe[i] = float(metrics.MMD_unweighted(pred_stat_rnpe, obs_stat, lengthscale=1))\n",
    "\n",
    "    # npe_rs\n",
    "    root_name = f\"objects/NPE/ricker_final/degree=0.2_mmd_beta=5.0_theta=[4, 25]_num=1000/{i+1}\"\n",
    "    _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "    post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_mmd)\n",
    "\n",
    "    predictive_data_npe_rs = torch.zeros(n_samples_mmd, n_length_ricker)\n",
    "    for j in range(n_samples_mmd):\n",
    "        predictive_data_npe_rs[j] = simulator(post_samples_npe_rs[j])[0]\n",
    "\n",
    "    pred_stat_npe_rs = torch.tensor(temporalMomentsGeneral(predictive_data_npe_rs))\n",
    "\n",
    "    mmd_npe_rs[i] = float(metrics.MMD_unweighted(pred_stat_npe_rs, obs_stat, lengthscale=1))\n",
    "\n",
    "print(f\"Ricker prior misspecification\")\n",
    "print(f\"NPE: MMD mean={np.mean(mmd_npe[~np.isnan(mmd_npe)])}, MMD std={np.std(mmd_npe[~np.isnan(mmd_npe)])}\")\n",
    "print(f\"RNPE: MMD mean={np.mean(mmd_rnpe[~np.isnan(mmd_rnpe)])}, MMD std={np.std(mmd_rnpe[~np.isnan(mmd_rnpe)])}\")\n",
    "print(f\"NPE-RS: MMD mean={np.mean(mmd_npe_rs[~np.isnan(mmd_npe_rs)])}, MMD std={np.std(mmd_npe_rs[~np.isnan(mmd_npe_rs)])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf34d3e",
   "metadata": {},
   "source": [
    "## Turin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "860fc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations_turin = 100\n",
    "n_length_turin = 801\n",
    "\n",
    "n_samples_mmd = 1000\n",
    "n_sim = 20\n",
    "\n",
    "simulator = turin(B=4e9, Ns=801, N=1, tau0=0)\n",
    "\n",
    "# for turin, we need new posterior\n",
    "def load_models(root_name: str, device: torch.device):\n",
    "    sum_net = torch.load(\"{root_name}/sum_net.pkl\".format(root_name=root_name), map_location=device)\n",
    "\n",
    "    density_estimator = torch.load(\"{root_name}/density_estimator.pkl\".format(root_name=root_name), map_location=device)\n",
    "\n",
    "    with open(\"{root_name}/posterior_new.pkl\".format(root_name=root_name), \"rb\") as handle:\n",
    "        posterior = CPU_Unpickler(handle).load() if device == torch.device('cpu') else pickle.load(handle)\n",
    "    \n",
    "    return sum_net, density_estimator, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f1009c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalMomentsGeneral_turin(Y, K=4, B=4e9):\n",
    "    N, Ns = Y.shape\n",
    "    delta_f = B / (Ns - 1)\n",
    "    t_max = 1 / delta_f\n",
    "    tau = np.linspace(0, t_max, Ns)\n",
    "    out = np.zeros((N, K))\n",
    "    for k in range(K):\n",
    "        for i in range(N):\n",
    "            y = np.fft.ifft(Y[i, :])\n",
    "            out[i, k] = np.trapz(tau ** (k) * (np.abs(y) ** 2), tau)\n",
    "    return np.log(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758cab0",
   "metadata": {},
   "source": [
    "### Turin MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40917ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.tensor(np.load(f\"data/turin_obs.npy\"))\n",
    "\n",
    "obs_stat = torch.tensor(temporalMomentsGeneral_turin(Y=obs.reshape(n_realizations_turin, n_length_turin)))\n",
    "mmd_npe = np.zeros(n_sim)\n",
    "mmd_rnpe = np.zeros(n_sim)\n",
    "mmd_npe_rs = np.zeros(n_sim)\n",
    "for i in range(0, n_sim):\n",
    "    print(i)\n",
    "    # npe\n",
    "    root_name = f\"objects/NPE/turin_final/none_beta=2.0_num=2000_N=100_tau0/{i+1}\"\n",
    "    _, _, posterior_npe = load_models(root_name, device)\n",
    "    post_samples_npe = sample_posteriors(posterior_npe, obs, n_samples_mmd)\n",
    "\n",
    "    predictive_data_npe = torch.zeros(n_samples_mmd, n_length_turin)\n",
    "    for j in range(n_samples_mmd):\n",
    "        predictive_data_npe[j] = simulator(post_samples_npe[j])[0]\n",
    "\n",
    "    pred_stat_npe = torch.tensor(temporalMomentsGeneral_turin(predictive_data_npe))\n",
    "\n",
    "    mmd_npe[i] = float(metrics.MMD_unweighted(pred_stat_npe, obs_stat, lengthscale=1))\n",
    "\n",
    "    # rnpe\n",
    "    post_samples_rnpe = torch.tensor(read_rnpe(model=\"turin\", var=1, degree=0, seed=i+1, theta='[0,0]'))[:n_samples_mmd]\n",
    "    \n",
    "    predictive_data_rnpe = torch.zeros(n_samples_mmd, n_length_turin)\n",
    "    for j in range(n_samples_mmd):\n",
    "        predictive_data_rnpe[j] = simulator(post_samples_rnpe[j])[0]\n",
    "\n",
    "    pred_stat_rnpe = torch.tensor(temporalMomentsGeneral_turin(predictive_data_rnpe))\n",
    "\n",
    "    mmd_rnpe[i] = float(metrics.MMD_unweighted(pred_stat_rnpe, obs_stat, lengthscale=1))\n",
    "\n",
    "    # npe_rs\n",
    "    root_name = f\"objects/NPE/turin_final/mmd_beta=2.0_num=2000_N=100_tau0/{i+1}\"\n",
    "    _, _, posterior_npe_rs = load_models(root_name, device)\n",
    "    post_samples_npe_rs = sample_posteriors(posterior_npe_rs, obs, n_samples_mmd)\n",
    "\n",
    "    predictive_data_npe_rs = torch.zeros(n_samples_mmd, n_length_turin)\n",
    "    for j in range(n_samples_mmd):\n",
    "        predictive_data_npe_rs[j] = simulator(post_samples_npe_rs[j])[0]\n",
    "\n",
    "    pred_stat_npe_rs = torch.tensor(temporalMomentsGeneral_turin(predictive_data_npe_rs))\n",
    "\n",
    "    mmd_npe_rs[i] = float(metrics.MMD_unweighted(pred_stat_npe_rs, obs_stat, lengthscale=1))\n",
    "\n",
    "print(f\"Turin model\")\n",
    "print(f\"NPE: MMD mean={np.mean(mmd_npe[~np.isnan(mmd_npe)])}, MMD std={np.std(mmd_npe[~np.isnan(mmd_npe)])}\")\n",
    "print(f\"RNPE: MMD mean={np.mean(mmd_rnpe[~np.isnan(mmd_rnpe)])}, MMD std={np.std(mmd_rnpe[~np.isnan(mmd_rnpe)])}\")\n",
    "print(f\"NPE-RS: MMD mean={np.mean(mmd_npe_rs[~np.isnan(mmd_npe_rs)])}, MMD std={np.std(mmd_npe_rs[~np.isnan(mmd_npe_rs)])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cabbb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
