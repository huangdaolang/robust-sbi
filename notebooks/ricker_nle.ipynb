{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1781b262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from sbi.inference.snle.snle_a import SNLE_A\n",
    "from sbi.inference.base import *\n",
    "import sbi.utils as utils\n",
    "from sbi.utils.get_nn_models import *\n",
    "from sbi.utils.sbiutils import *\n",
    "from sbi.utils.torchutils import *\n",
    "from sbi.inference.base import infer\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n",
    "from pyknos.nflows import flows\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from simulators.ricker import ricker\n",
    "from utils.metrics import RMSE\n",
    "from utils.plot_config import update_plot_style\n",
    "import io\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14875919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalMomentsGeneral(Y, K=3, B=4e9):\n",
    "    N, Ns = Y.shape\n",
    "    tau = np.linspace(0, 100, Ns)\n",
    "    out = np.zeros((N, K))\n",
    "    Y = Y.detach().numpy()\n",
    "    for k in range(K):\n",
    "        for i in range(N):\n",
    "            out[i, k] = np.trapz(tau**(k) * Y[i], tau) + 1e-4\n",
    "    return np.log(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc08064",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 1000\n",
    "N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c4ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cont = torch.tensor(np.load(f\"../data/ricker_obs_1.npy\")).to(device)\n",
    "\n",
    "theta = torch.tensor(np.load(\"../data/ricker_theta_1000.npy\")).to(device)\n",
    "x = torch.tensor(np.load(\"../data/ricker_x_1000.npy\")).reshape(num_simulations, N, 100).to(device)\n",
    "\n",
    "dataloader = DataLoader(x, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9899c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = [Uniform(2 * torch.ones(1).to(device), 8 * torch.ones(1).to(device)),\n",
    "         Uniform(torch.zeros(1).to(device), 20 * torch.ones(1).to(device))]\n",
    "prior_new = [Uniform(2 * torch.ones(1).to(device), 8 * torch.ones(1).to(device)),\n",
    "         Uniform(torch.zeros(1).to(device), 80 * torch.ones(1).to(device))]\n",
    "\n",
    "simulator, prior = prepare_for_sbi(ricker(N=N), prior)\n",
    "simulator, prior_new = prepare_for_sbi(ricker(N=N), prior_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec0d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RickerSummary(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(RickerSummary, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Conv1d(self.input_size, 4, 3, 4),\n",
    "                                     nn.Conv1d(4, 4, 3, 4),\n",
    "                                     nn.Conv1d(4, 4, 3, 4),\n",
    "                                     )\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.ConvTranspose1d(4, 4, 3, 4),\n",
    "                                     nn.ConvTranspose1d(4, 4, 3, 4),\n",
    "                                     nn.ConvTranspose1d(4, self.input_size, 3, 4),\n",
    "                                     nn.Upsample(100)\n",
    "                                     )\n",
    "\n",
    "    def forward(self, Y):\n",
    "        embeddings = self.encoder(Y.reshape(-1, 1, 100))\n",
    "        output = self.decoder(embeddings.reshape(-1, 4, 1)).reshape(-1, 100, 100)\n",
    "        return output\n",
    "    \n",
    "    def forward_encoder(self, Y):\n",
    "        embeddings = self.encoder(Y.reshape(-1, 1, 100)).reshape(-1, 100, 4)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5fdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_normal():\n",
    "    summary_net_normal = RickerSummary(1, 4).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(summary_net_normal.parameters(), lr=0.01)\n",
    "\n",
    "    # Train the model for some number of epochs\n",
    "    num_epochs = 10\n",
    "    time_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for data in dataloader:\n",
    "            start_time = time.time()\n",
    "            inputs = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = summary_net_normal(inputs)\n",
    "\n",
    "            loss = criterion(outputs, inputs) / 10000\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")\n",
    "    return summary_net_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c4c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_robust(beta, obs_cont):\n",
    "    summary_net_robust = RickerSummary(1, 4).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(summary_net_robust.parameters(), lr=0.01)\n",
    "\n",
    "    index_list = [int(i) for i in range(len(x))]\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for data in dataloader:\n",
    "            inputs = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = summary_net_robust(inputs)\n",
    "\n",
    "            random.shuffle(index_list)\n",
    "            context_embeddings = torch.mean(summary_net_robust.forward_encoder(x[index_list[:200]]), dim=1)\n",
    "            obs_embeddings = torch.mean(summary_net_robust.forward_encoder(obs_cont), dim=1)\n",
    "\n",
    "            ae_loss = criterion(outputs, inputs) / 10000\n",
    "            summary_loss = metrics.MMD_unweighted(context_embeddings, obs_embeddings, lengthscale=metrics.median_heuristic(context_embeddings))\n",
    "\n",
    "            loss = ae_loss + beta*summary_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")\n",
    "    return summary_net_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbdf9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 18.409171104431152\n",
      "Epoch 2, Loss: 18.078046607971192\n",
      "Epoch 3, Loss: 16.805509185791017\n",
      "Epoch 4, Loss: 13.82416648864746\n",
      "Epoch 5, Loss: 13.2974702835083\n",
      "Epoch 6, Loss: 12.692077159881592\n",
      "Epoch 7, Loss: 12.869472885131836\n",
      "Epoch 8, Loss: 12.642597198486328\n",
      "Epoch 9, Loss: 12.64726676940918\n",
      "Epoch 10, Loss: 12.586797142028809\n"
     ]
    }
   ],
   "source": [
    "summary_net_normal = solve_normal()\n",
    "\n",
    "x_summary = torch.sum(summary_net_normal.forward_encoder(x), dim=1).cpu().detach().numpy()\n",
    "obs_summary = torch.sum(summary_net_normal.forward_encoder(obs_cont), dim=1)\n",
    "\n",
    "theta = theta.to(device)\n",
    "\n",
    "inference_normal = SNLE_A(prior=prior, device='cpu')\n",
    "density_estimator_normal = inference_normal.append_simulations(theta=theta, x=torch.tensor(x_summary).to(device))\n",
    "density_estimator_normal.train()\n",
    "\n",
    "posterior_normal = inference_normal.build_posterior(prior=prior_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ae968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 18.804403686523436\n",
      "Epoch 2, Loss: 17.69242706298828\n",
      "Epoch 3, Loss: 14.976074600219727\n",
      "Epoch 4, Loss: 13.736443901062012\n",
      "Epoch 5, Loss: 13.227659797668457\n",
      "Epoch 6, Loss: 13.415997886657715\n",
      "Epoch 7, Loss: 13.16824893951416\n",
      "Epoch 8, Loss: 13.171481895446778\n",
      "Epoch 9, Loss: 13.08675537109375\n",
      "Epoch 10, Loss: 13.099022483825683\n",
      " Neural network successfully converged after 413 epochs."
     ]
    }
   ],
   "source": [
    "summary_net_ours = solve_robust(3, obs_cont)\n",
    "\n",
    "x_summary_robust = torch.sum(summary_net_ours.forward_encoder(x), dim=1).cpu().detach().numpy()\n",
    "obs_summary_robust = torch.sum(summary_net_ours.forward_encoder(obs_cont), dim=1)\n",
    "\n",
    "theta = theta.to(device)\n",
    "inference_robust = SNLE_A(prior=prior, device='cpu')\n",
    "density_estimator_robust = inference_robust.append_simulations(theta=theta, x=torch.tensor(x_summary_robust).to(device))\n",
    "density_estimator_robust.train()\n",
    "\n",
    "posterior_robust = inference_robust.build_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b52be20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ee2e4926144e8aadf59bd967191af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec09679cc5b74d89b229ad2ef66adbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robust_samples = posterior_robust.sample([100], obs_summary_robust)\n",
    "normal_samples = posterior_normal.sample([100], obs_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1998416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE normal 9.191390037536621\n",
      "RMSE robust 3.748779535293579\n"
     ]
    }
   ],
   "source": [
    "theta_gt = torch.tensor([4, 10])\n",
    "print(\"RMSE normal\", float(RMSE(theta_gt, normal_samples, p=2)))\n",
    "print(\"RMSE robust\", float(RMSE(theta_gt, robust_samples, p=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98c1a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd normal 0.8686911479283871\n",
      "mmd robust 0.1915174432457829\n"
     ]
    }
   ],
   "source": [
    "ricker_simulator = ricker(N=1)\n",
    "obs_stat = torch.tensor(temporalMomentsGeneral(obs_cont.reshape(100, 100)))\n",
    "\n",
    "predictive_data_normal = torch.zeros(100, 100)\n",
    "predictive_data_robust = torch.zeros(100, 100)\n",
    "for j in range(100):\n",
    "    predictive_data_normal[j] = ricker_simulator(normal_samples[j])[0]\n",
    "    predictive_data_robust[j] = ricker_simulator(robust_samples[j])[0]\n",
    "\n",
    "pred_stat_normal = torch.tensor(temporalMomentsGeneral(predictive_data_normal))\n",
    "pred_stat_robust = torch.tensor(temporalMomentsGeneral(predictive_data_robust))\n",
    "\n",
    "mmd_normal = float(metrics.MMD_unweighted(pred_stat_normal, obs_stat, lengthscale=1))\n",
    "mmd_robust = float(metrics.MMD_unweighted(pred_stat_robust, obs_stat, lengthscale=1))\n",
    "\n",
    "print(\"mmd normal\", mmd_normal)\n",
    "print(\"mmd robust\", mmd_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ab7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sns.jointplot(x=normal_samples[:, 0], y=normal_samples[:, 1],\n",
    "                 cmap=\"Oranges\", kind=\"kde\", height=4, marginal_kws={\"color\":\"C1\", \"alpha\":.5, \"shade\":True}, shade=True, thresh=0.05, alpha=.5,\n",
    "                 label='NLE')\n",
    "\n",
    "\n",
    "graph.x = robust_samples[:, 0]\n",
    "graph.y = robust_samples[:, 1]\n",
    "graph.plot_joint(sns.kdeplot, cmap=\"Blues\", shade=True, alpha=.5, label='Ours')\n",
    "graph.ax_joint.axvline(x=theta_gt[0], lw=1, ls=\"-\",c=\"black\", label=\"True $\\\\theta$\")\n",
    "graph.ax_joint.axhline(y=theta_gt[1], lw=1, ls=\"-\",c=\"black\")\n",
    "\n",
    "graph.ax_joint.axvline(x=2, ls=\"--\", lw=1, c=\"gray\", alpha=0.3)\n",
    "graph.ax_joint.axvline(x=8, ls=\"--\", lw=1, c=\"gray\", alpha=0.3)\n",
    "\n",
    "graph.ax_joint.axhline(y=0, ls=\"--\", lw=1,c=\"gray\", alpha=0.3)\n",
    "graph.ax_joint.axhline(y=20, ls=\"--\", lw=1, c=\"gray\", alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "legend_elements = [Line2D([0], [0], color='k', lw=1, label='True $\\\\theta$'),\n",
    "                   Patch(facecolor='C0', edgecolor='C0',\n",
    "                         label='Ours'),\n",
    "                   Patch(facecolor='C1', edgecolor='C1',\n",
    "                         label='NLE')]\n",
    "\n",
    "\n",
    "graph.ax_joint.legend(handles=legend_elements, loc='upper right', fontsize=10) \n",
    "\n",
    "\n",
    "graph.ax_joint.set_xlabel('$\\\\theta_1$')\n",
    "graph.ax_joint.set_ylabel('$\\\\theta_2$')\n",
    "\n",
    "graph.plot_marginals(sns.kdeplot, color='C0', shade=True, alpha=.5, legend=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"NLE_posterior.pdf\", dpi = 300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
